# -*- coding: utf-8 -*-
"""music_recommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17AvZutHiP_4DiFZ6cQS46OPgr_6PElDX

# Music Recommendation (Spotify)

## Import Required Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from google.colab import files
import os
import shutil
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_squared_error, mean_absolute_error
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
warnings.filterwarnings('ignore')

"""## Data Preparation

### Loading Data
"""

# uploaded = files.upload()

# kaggle_dir = os.path.expanduser('~/.kaggle')
# os.makedirs(kaggle_dir, exist_ok=True)

# # Pindahkan file kaggle.json
# shutil.move('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))

# # Atur permission file
# os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)

# !kaggle datasets download -d maharshipandya/-spotify-tracks-dataset

# !unzip /content/-spotify-tracks-dataset.zip

data = pd.read_csv("dataset.csv")

data.tail()

unique_genres = data['track_genre'].unique()
print(unique_genres)
print(f"Number of unique genres: {len(unique_genres)}")

data.columns

print("Numbers of Rows and Columns:")
data.shape

"""### Dropping Duplicate Values"""

# Check for duplicates based on 'track_id'
duplicates = data[data.duplicated(subset=['track_id'])]

# Display the duplicated rows
print("Duplicated rows based on 'track_id':")
print(duplicates)

# Count the number of duplicates
num_duplicates = len(duplicates)
print(f"\nNumber of duplicated track IDs: {num_duplicates}")

# Display rows before dropping duplicates
print("Rows before dropping duplicates:")
print(data.shape[0])

# Drop duplicate rows based on all columns
data_no_duplicates = data.drop_duplicates(subset='track_id')


# Display rows after dropping duplicates
print("\nRows after dropping duplicates:")
data_no_duplicates.shape[0]

"""### Dropping Missing Values"""

# Display number of missing values in each column
print("\nMissing values per column:")
print(data_no_duplicates.isnull().sum())

# Drop rows with any missing values
data = data_no_duplicates.dropna()

# Display the shape of the DataFrame after dropping missing values
print("\nShape of DataFrame after dropping missing values:")
data.shape

"""### Drop Unrelevant Columns"""

data = data.drop('Unnamed: 0', axis=1)

# Now 'data' DataFrame does not have the 'Unnamed: 0' column
data.columns

"""## Modelling

### 1. Using K-Nearest Neighbors based on Song Features

These features should represent song characteristics.
"""

# Select the relevant features for the model
X = data[['danceability', 'energy', 'loudness', 'tempo', 'valence']]

"""Create and Train the KNN Model"""

from sklearn.neighbors import NearestNeighbors

# Initialize the KNN model
knn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')

# Fit the model on the features
knn.fit(X)

"""Define the Recommendation Function"""

def recommend_tracks_by_name(track_name, n_recommendations=5):
    """
    Recommend similar tracks based on KNN using track_name.

    Parameters:
        track_name (str): Name of the track for which recommendations are made.
        n_recommendations (int): Number of recommendations to return (default 5).

    Returns:
        pd.DataFrame: Recommended tracks with track name, artist, and genre.
    """
    # Check if track_name exists in the dataset
    if track_name in data['track_name'].values:
        # Get the index of the track in the dataset
        idx_data = data[data['track_name'] == track_name].index[0]

        # Get the index in the feature matrix (X)
        idx_X = X.index.get_loc(idx_data)

        # Find nearest neighbors using KNN
        distances, indices = knn.kneighbors([X.iloc[idx_X]], n_neighbors=n_recommendations + 1)

        # Extract recommended tracks
        recommended_tracks = data.iloc[indices[0][1:]]
        return recommended_tracks[['track_name', 'artists', 'track_genre']]
    else:
        print(f"Track name '{track_name}' not found in the dataset.")
        return None

""" Test the Recommendation Function"""

# Test the function with a specific track ID
recommendations =recommend_tracks_by_name('Call It Fate, Call It Karma')

# Display the recommendations
recommendations

"""### 2. Using Cosine Similarity based on Track Genre"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data
tf.fit(data['track_genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['track_genre'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

#Tampilkan dalam DataFrame
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.track_name
).sample(22, axis=1).sample(10, axis=0)

"""Sekarang, kita akan menghitung derajat kesamaan (similarity degree) antar musik dengan teknik cosine similarity."""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['track_name'], columns=data['track_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def music_recommendations(nama_track, similarity_data=cosine_sim_df, items=data[['track_name', 'track_genre','artists']], k=5):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_track].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    # Convert 'index' to 1D array before using it to index 'similarity_data.columns'
    closest = similarity_data.columns[index[-1:-(k+2):-1].ravel()]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_track, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

data[data.track_name.eq('Call It Fate, Call It Karma')]

music_recommendations('Call It Fate, Call It Karma')